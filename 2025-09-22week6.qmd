---
title: "2025-09-22"
format:
  html: default
  pdf: default
params:
  course: "mc451"
  word_min: 250
  word_max: 300
  p1: 'Think of a broad media-related topic you’ve been curious about—something like influencer culture, algorithmic feeds, or news bias. Now, imagine you’re preparing to research this topic. Would you start with a research question or a hypothesis? Why? Reflect on how much you already know (or don’t know) about the topic, and how that affects whether exploration or prediction is the better fit.'
 
---

## Choose **one** prompt to answer

> **Prompt A:** `r params$p1`



---

## Response

<!-- RESPONSE-START -->
If I were to preparing to research the algorithmic feeds on social media, I would begin by developing a research question first before I even aim for a hypothesis. According to the chapter we read this week, there are key distinctions between a research question and a hypothesis. The main one is that it hinges on how much prior knowledge exists and whether the reasearcher aims at "exploration" or "prediction." I have some prior knowledge of how algorithmic feeds function, such as engagement-based ranking and filter bubbles, but I lack detailed and systematic evidence on the broader consquences, such as impacts on political polarization, mental health, or knowledge diversity.Because of that lack of depth, the study is more exploratory. A research question, such as "How does use of algorithmic feeds affect exposure to diverse political viewpoints among users on social media?" fits well. It allows me to explore, explain, and make sense of the issue without locking myself into a conclusion too early.This matches the textbook's point that research questions are most useful when existing studies are limited, inconsistent, or when the subject is relatively new. Only once enough groundwork has been laid (either through a literature review or pilot studies) and I begin seeing patterns would it then make sense for me to formulate a hypothesis. Developing a hypothesis depends on having enough research or theory to suggest a specific effect-- for instance, that algorithmic feeds limit political diversity-- but I don't yet have the basis to make that prediction. In short, because I am in the exploration stage rather than prediction, a research question is the stronger starting point.
<!-- RESPONSE-END -->

---

## Word Count & Range Check

```{r}
#| echo: false
#| message: false
#| warning: false
get_response_text <- function() {
  f <- knitr::current_input()
  if (is.null(f) || !file.exists(f)) return("")
  x <- readLines(f, warn = FALSE)
  # Find the lines that EXACTLY match the start/end markers
  s <- grep("^<!-- RESPONSE-START -->$", x)
  e <- grep("^<!-- RESPONSE-END -->$", x)
  if (length(s) != 1 || length(e) != 1 || e <= s) return("")
  paste(x[(s + 1L):(e - 1L)], collapse = "\n")
}
count_words <- function(txt) {
  # Remove code blocks and inline code before counting
  txt <- gsub("```[\\s\\S]*?```", " ", txt, perl = TRUE)
  txt <- gsub("`[^`]*`", " ", txt, perl = TRUE)
  # Keep letters, numbers, spaces, hyphens, and apostrophes
  txt <- gsub("[^\\p{L}\\p{N}\\s'-]", " ", txt, perl = TRUE)
  # Split by whitespace and count non-empty words
  words <- unlist(strsplit(txt, "\\s+", perl = TRUE))
  words <- words[nzchar(words)]
  length(words)
}
txt <- get_response_text()
n <- count_words(txt)
minw <- as.integer(params$word_min)
maxw <- as.integer(params$word_max)
in_range <- n >= minw && n <= maxw
cat(sprintf("**Word count:** %d  \n", n))
cat(sprintf("**Required range (%s):** %d–%d words  \n",
            toupper(params$course), minw, maxw))
cat(if (in_range) "**Status:** ✅ In range\n" else "**Status:** ❌ Out of range\n")
```
